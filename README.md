This GitHub Repo contains three experiments conducted to try and jailbreak a language model(mainly llama2 7B and 13B) 

There are 3 folders for each of my experiments in this GitHub repo.

Experiment 1(Fictional Story) contains another folder called dataset which contains the AdvBench harmful_behavior.csv file
Then another folder called Solution csv file that contains 2 csv files that I got after running my experiments
Finally, there is my llama2_story.ipynb notebook that contains the source code for my experiment

Experiment 3(System Prompt) contains A notebook file, a csv file containing 15 prompts of harmful behavior from the 
AdvBench dataset and the resulted csv file in the name updated_harmful_15.csv
